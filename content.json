{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://aifengdudexiaojie.github.io","root":"/"},"pages":[],"posts":[{"title":"Wavelet Channel Attention","slug":"Wave-Channel-Attention","date":"2023-05-24T00:50:10.000Z","updated":"2023-05-25T02:18:09.260Z","comments":true,"path":"2023/05/24/Wave-Channel-Attention/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/05/24/Wave-Channel-Attention/","excerpt":"","text":"WaveNets: Wavelet Channel Attention Networks问题：通道注意力有效，但是所提出的SENet在使用GAP全局平均池化时是丢信息的。解决：设计有效的通道注意力机制以增强 模型通道内部依赖的 特征留存。 该工作用小波来解决信道问题。首先测试小波作为 一个编码模型 with 卷积通道注意力模块。然后测试小波作为 一个独立的压缩通道方法。 证明了全局池化等价于 递归近似哈尔小波变换 在此基础上，我们利用小波压缩技术推广了信道注意，并将其命名为WaveNet。 引言现有的观点认为GAP的使用阻碍了通道注意力的性能，GAP不能保留复杂的细节，也不符合一些任务的模型实践。GAP的直接降维进一步限制了CA的通道间依赖性建模[8] 我们设计WaveNet的动机源于我们需要重新评估CA，以在特征学习中捕获更精细的细节。这种重新评估应该允许CA重新分配输入特征图的权值，以提高分类精度，同时保持CA的计算效率。 解决方案： 通过离散小波变换DWT来增强下采样过程中的特征保存。 低通（LL）、水平（LH）、垂直（HL）和对角（HH） LL滤波器对应于具有较低分辨率的原始图像的缩小版本，而LH、HL和HH带通滤波器突出了输入在其相关方向上的主要特征。DWT在图像上进行多层次分解的能力启发了WaveNet，其中我们探索了DWT在CA中的应用的分解层次。 我们建议利用Haar DWT进行信道注意机制。结合Haar信道注意框架，我们提出了一个定制的小波信道注意框架。在这个框架中，我们使用了一组随机正交滤波器，用于自定义小波。这些正交滤波器的作用是在激发通道注意之前，在压缩任务中加强特征保持和多样性。 贡献： 从压缩的角度看待通道注意力，并在普通通道注意力中采用DWT来保存通道信息。【证明了常规的GAP是离散Haar小波的递归近似分量，并从频率基础上推广了信道注意力。】 基于Haar，提出了WaveNet-C，一种自定义的正交线性独立滤波器小波，以增强信道注意力压缩任务的多样性， 相关工作[46]提出了由注意力嵌入网络和小波嵌入网络组成的WAEN来提高视频的超分辨率 AWNet [45]将非局部关注与DWT集成 在[47]中提出的基于软注意的模型应用DWT来改进变形图像的人脸识别。 [48]提出了一个检测玻璃瓶表面缺陷的框架，该框架将小波变换融合成它们的视觉注意模型。 [49]详细介绍了一个基于DWT融合网络的单一图像分层模型，并将其反向输入其注意模块。 早期的相关工作往往忽视了注意机制的使用，其范围从图像超分辨率的[39]，[40]，修复[43]，演示[44]，和修复[12]。","categories":[],"tags":[{"name":"paper wavelet","slug":"paper-wavelet","permalink":"http://aifengdudexiaojie.github.io/tags/paper-wavelet/"}]},{"title":"Wave Channel Attention","slug":"Wavelet-Channel-Attention","date":"2023-05-24T00:50:10.000Z","updated":"2023-05-24T00:50:56.940Z","comments":true,"path":"2023/05/24/Wavelet-Channel-Attention/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/05/24/Wavelet-Channel-Attention/","excerpt":"","text":"","categories":[],"tags":[{"name":"paper wavelet","slug":"paper-wavelet","permalink":"http://aifengdudexiaojie.github.io/tags/paper-wavelet/"}]},{"title":"Wavelet Network with KD for RGB-T SOD","slug":"Wavelet-Network-with-KD-for-RGB-T-SOD","date":"2023-05-23T07:35:34.000Z","updated":"2023-05-23T13:08:50.622Z","comments":true,"path":"2023/05/23/Wavelet-Network-with-KD-for-RGB-T-SOD/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/05/23/Wavelet-Network-with-KD-for-RGB-T-SOD/","excerpt":"","text":"WaveNet: Wavelet Network with Knowledge Distillation for RGB-T Salient Object DetectionRGB-T中T为红外图像离散小波变换允许检查局域时域的频域特征和局域频域的时域特征。我们应用这种表示能力来执行跨模态特征融合。具体来说，我们引入了一个渐进级联的正弦-余弦模块用于跨层特征融合，并使用低层次特征通过MLP获得突出对象的清晰边界。 由于CNN带来的下采样信息损失，需要将边界特征通过专用的感知模块来提取以去除噪声。 贡献： 提出使用Wave-MLP主干的WaveNet。应用离散小波变换对RGB-T模态的特征进行集成。提出了一种逐步扩展的正弦余弦模块用于跨层余弦特征融合。 利用知识蒸馏 所提出的方法：交叉模态信息融合 和 多层解码 为提高学习水平使用知识蒸馏来指导网络WaveNet。此外，边界检测模块为监督提供了边界信息，相似性监督减少了模式之间的特征差异。 DWT模块问题：RGB-T图像由于不同的成像机制而包含丰富的互补信息。但是存在形态差异。这阻碍了信息的融合和效用。为此，应用了DWT。使用二进制离散处理方法，将离散小波及其变换集成到新的DWT模块中。这提供了一个强大的光谱分析工具。DWT允许我们检查局部时域的频域特征和局部频域的时域特征。该变换离散了基本小波的尺度和平移，并将一幅图像表示为一系列的小波系数。 具体内容：DWT模块的体系结构如图4所示。首先，利用DWT从RGB和热红外数据中得到低通（xl、yl）和高通（xh、yh）系数。低频分量在不同的数据中很重要，因为它们通常包含一般特征，而高频分量则包括细节。我们融合了RGB的低频分量和热红外特征，然后将逆DWT应用于融合的特征，重建DWT信息，最终将其集成到网络中，以提高SOD。DWT模块完全结合了RGB和热红外模式的特征图，将其结果应用于边界模块和解码阶段。 级联正弦波Sine-Wave模块DWT模块提供了跨模态和跨级别的融合特性。高级特征分辨率小 通道过 包含丰富的语义低级特征分辨率高 通道少 包含细节和边界此外，上下文信息对RGB-T SOD也至关重要。因此，我们采用渐进式拉伸策略来捕获全局和局部信息。 正余弦函数是可以用来分割信号的最简单小波。它们可以捕获具有可变大小的对象或各种显著对象，从而提供上下文信息。《上下文信息由此捕获？》 所提出的级联正弦波（CSW）模块的体系结构如图5所示，它包含三个分支：两个分支用膨胀卷积捕获周边信息。相邻的两个分支通过正余弦模块提供跨尺度信息，并对齐。同时这三个分支的输出呗添加用以传递上下文信息。 由于CSW模块可能产生冗余信息，我们通过辍学来丢弃它，并使用转置的卷积[79]来调整特征的通道大小和数量。我们将结果传输到下一层进行解码。 EAM边界信息用于勾勒出一个突出的对象，这对于突出对象定位是必要的。","categories":[],"tags":[{"name":"wavelet sod","slug":"wavelet-sod","permalink":"http://aifengdudexiaojie.github.io/tags/wavelet-sod/"}]},{"title":"Dual-branch deep image prior for image denoising","slug":"Dual-branch-deep-image-prior-for-image-denoising","date":"2023-05-15T12:58:24.000Z","updated":"2023-05-17T03:34:45.577Z","comments":true,"path":"2023/05/15/Dual-branch-deep-image-prior-for-image-denoising/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/05/15/Dual-branch-deep-image-prior-for-image-denoising/","excerpt":"","text":"Dual-branch deep image prior for image denoising提出一种两阶段的去噪方式：generation 生成 and fusion 融合生成阶段：首先将标准的DIP deep image prior 深度先验网络的UNet主干网络扩展为两个分支，将其转换为YNet，后采用动态注意力图学习DAGL 和 恢复器方法获得的初始去噪图像。最后，我们利用标准的DIP在线训练程序，利用一种新的自动迭代终止机制，生成两个互补的基本图像，其图像质量得到了很大的提高。融合阶段：首先将标准UNet网络的收缩路径分成两个分支，以接收前一阶段生成的两个基本图像，并以完全无监督的方式得到一个融合图像作为最终的去噪图像。 所提出的混合策略的性能显著提高，即首先采用监督去噪方法对图像的公共内容进行大量处理，然后利用无监督方法对具体细节进行微调。即，我们充分利用了有监督方法的高性能和无监督方法的灵活性 R2R (Recorrupted-to-Recorrupted)方法通过添加不同的噪声，分别构建了一个基于有噪声到有噪声的图像pairs。 该训练方式得到的去噪模型等价于一个从噪声-干净的图像pairsR2R方法对真实图像的去噪效果优于N2N (noise2noise)等无监督去噪方法，但与有监督方法相比存在较大的差距。虽然上述无监督方法可以解决训练图像对不容易采集的问题，但仍然需要大量的噪声图像进行去噪，这在现实世界中是一项困难的任务。 DIP 深度图像先验 的无监督方法:只需要一个有噪声的图像和一个合适的网络结构（即UNet）来完成图像去噪任务，具有很大的灵活性。将迭代优化方案与DNNs的先验建模能力相结合。 文章提出一种渐进的双分支U型网络&#x3D;&gt;YNet，以提高DIP方法的性能。所提去噪方法DBDIP：分割经典UNet的解码器（扩展路径）或编码器（收缩路径），采用YNet作为主干网络。 在图像生成阶段我们首先选择两个高度互补的监督去噪模型，即DAGL和Restormer，分别对给定的噪声图像进行实质性的去噪。相应地，我们得到了两个去噪图像，称为初始去噪图像，它们作为目标图像与给定的噪声图像一起工作。然后将UNet的路径扩展为两个分支，分别近似于两个初始去噪图像和有噪图像。于DIP方法相似，有噪声图像仍然作为目标target图像。 采用标准的DIP在线无监督训练程序通过让YNet的输出图像近似于目标图像。沿两个分支生成两个基本图像。同时，为了防止DIP的过拟合，利用SSIM损失函数设计了一种新的自适应迭代终止机制以代替DIP原有的固定步数停止机制。最后，我们可以在不需要监测PSNR（峰值信噪比）的情况下，获得两幅高质量的基本图像。 在融合阶段： 对UNet进行改进，用收缩路径代替扩展路径，以接受前一个阶段生成的两个基本图像。然后再次进行标准的DIP在线无监督训练程序，生成一个融合的图像作为最终的去噪图像。 贡献： 通过分析有监督去噪和无监督去噪方法优缺点，提出一种混合的图像去噪策略。利用有监督的方法来获得初始去噪图像， 这意味着有噪声图像的公共内容首先由有监督的DNNs来处理。然后采用无监督DIP程序获得两幅基本图像，并将其融合为最终的去噪图像，即初始去噪图像由无监督dnn进行微调。在这项工作中，我们提供了一个有监督的桥梁和无监督的方法， 表明这两种范式之间可能存在协同作用。 标准的DIP方法受困于低质量的目标图像，即有噪图像和固定的迭代终止步骤等问题。该文选择两个网络以获得高度互补的初始去噪图像作为目标图像。处理 低质量 问题。同时用SSIM方法解决 固定步骤 问题。 融合阶段引入一种双分支无监督方法来融合前一阶段的生成的基本图像，以得到一个高质量的融合图。本文是首次尝试开发一种采用双分支架构的DIP方法的变体，它在去噪效果方面可以优于监督去噪器 相关工作：DIP方法应用到DNN，通过学习一个生成器网络来生成图像 出发点：目前的去噪网络没有哪一种可以在任何方面都超过其他网络。有的网络整体的PSNR处理效果好，有的局部恢复较好。因此，该文同时利用多个网络处理有噪图像以结合它们的优势并取得不错的鲁棒性。从而使用一个双分支网络结构。允许在一次运行中生成两个基本图像。以较小的成本 提高DIP方法性能。且路径，即迭代次数更少。 所提的DBDIP方法：生成阶段：DAGL和Restormer得到的初始去噪图像作为输入 DAGL和Restormer和噪声图像作为监督Loss func: 融合阶段：用带噪声的图像作为target 以已有网络的预测作为输入，将整个网络预测任务反过来处理。","categories":[],"tags":[{"name":"paper dual-branch denoising","slug":"paper-dual-branch-denoising","permalink":"http://aifengdudexiaojie.github.io/tags/paper-dual-branch-denoising/"}]},{"title":"BaMBNet:Blur-Aware Multi-Branch","slug":"BaMBNet-Blur-Aware-Multi-Branch","date":"2023-05-08T02:32:27.000Z","updated":"2023-05-09T02:53:14.833Z","comments":true,"path":"2023/05/08/BaMBNet-Blur-Aware-Multi-Branch/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/05/08/BaMBNet-Blur-Aware-Multi-Branch/","excerpt":"","text":"BaMBNet: A Blur-Aware Multi-Branch Network for Dual-Pixel Defocus Deblurring问题：以往的方法对离焦模糊图像的不同区域采用相同的学习核，因此难以处理非均匀的模糊图像。为此，本研究设计了一种新的模糊感知多分支网络（BaMBNet），对不同区域进行不同的处理 通过 dual-pixel(DP) data 内部几何约束 来评估不同区域的模糊量 &#x3D;&gt; 度量左右视图之间的散焦差异 不同模糊量的区域给予不同的困难假设。利用具有不同能力的网络来处理不同区域。同时引入了一种元学习meta-learning离焦掩模生成算法，将每个像素分配到一个适当的分支 这样，我们就可以在恢复模糊区域缺失细节的同时很好地保持模糊区域缺失的信息。 dual-pixel sensors DP传感器为每个像素位置提供一对光电二极管，以捕获同一场景[13]，[14]的两个子光径视图。&#x3D;&gt; 相比之前的单光敏二极管，提供了更多的信息。 目的：期望去模糊的结果是保留聚焦区域的细节，同时去除失焦区域的模糊。 网络问题：对于单一网络来说，在保持焦点区域的细节和保持失焦区域的去模糊之间取得平衡是一个巨大的挑战。 模糊量的计算评估： circle of confusion (COC) 一般模糊量与深度有关 掩膜的大致流程：在实际应用中，我们首先估计输入图像对的COC映射，然后通过元学习机制将COC映射转换为散焦掩模，将不同的图像像素分配到适当的分支网络中。学习参数较小的最轻分支：关注聚焦清晰区域。参数量最多的最重分支：重建缺失细节,并从具有大量模糊的区域恢复尖锐的部分。 贡献： 设计了一个模糊感知的多分支网络。不同的模糊区域含有不同模糊量，用不同的分支进行处理。以维护清晰区域的同时修复细节缺失区域 以无监督方式直接训练卷积网络，有效的改进了COC映射估计,从COC估计中生成掩膜，利用元学习策略。 相关工作：多分支网络：近年来，多分支网络在低级视觉任务中被探索，如超分辨率[27]−[29]、图像去噪[30]、[31]和单图像去模糊[32]。这些方法的基本思想是分治方案，其中每个像素都被单独处理。通过精心设计动态分支选择或特征融合策略，多分支网络在解决空间变化的图像重建问题上取得了巨大的成功。 【27】：【28】：【29】：【30】：【31】：【32】： 现有分支网络的限制：1.直接对区域进行划分，而不考虑数据的先验知识。2.存在分割操作，卷积层通常会破坏空间特征。 针对于此，使用COC映射显示地利用DP数据地特征优化多个分支网络，而将分割操作移动到输出，以避免丢失输入地语义信息。 Blur-Aware Multi-Branch Network：输入为6通道DP数据，即左右视角的图像。 推测的分区为：过近距离失焦区域 聚焦区域 过远距离失焦区域 剩余区域 主要的网络结构分为类FCN网络和UNet网络。 希望FCN网络聚焦于轻微模糊区域：不需要过大的感受野，更多的是保持区域的信息，去除一些轻微噪声。类Unet网络采用 残差信道注意力 模块RCAB(超分中广泛使用的基本单元) 三个类UNet的差别在于RCAB模块的数量。 LOSS Func：L1 COC 评估：首先6通道，左右视角的图 所包含的模糊核是对称的。 对应的COC估计图用Unet体系结构来训练网络。 阈值确定：离焦掩模生成可以转换为寻找一个图像的一些阈值，并将位置上的每个像素p分配给相应的掩模。首先，预定义最大和最小值的COC值。并设置一个最小间隔以得到一个候选集。为找到最优阈值，在一组没有使用过的小的训练数据上评估每个分支的去模糊性能。精确地，我们计算了每个分支在候选解集的每个最小区间上的重建损失。对于任何区间，当该分支的重建损失与该区间内的其他分支相比最小时，该分支是最优选择。对于整个数据集。 同时，为了让求解区间可连续，随着网络逐渐收敛，每个分支的大部分求解区域都被聚在一起。通过添加正则项以解决每个分支的离群区间。最后，对于每个分支，我们得到一组上界和下界，它们是求解的阈值集的元素，且阈值是连续的。在训练最终任务时，固定内部参数。 实验用于确定区间的小数据集 从训练集中取10%得到，而非使用验证集。 训练过程采用退火策略，即在训练早期让输出的预测结果重度依赖于掩膜，随着网络的收敛逐渐减少掩膜带来的影响，减少其权重直至为零。两个优点：1.网络可用自适应地优化整个图像。避免拼接时地不连续边缘。2.网络在测试阶段不需要掩膜部分网络，简化了网络的部署。 分支数量：2个分支和4个分支的PSNR和MAE评估结果相差无几。而4个分支的设置在SSIM和LPIPS方面表现较好。","categories":[],"tags":[{"name":"paper multi-branch defocus","slug":"paper-multi-branch-defocus","permalink":"http://aifengdudexiaojie.github.io/tags/paper-multi-branch-defocus/"}]},{"title":"Learning a Deep Dual Attention Network for Video Super-Resolution","slug":"Learning-a-Deep-Dual-Attention-Network-for-Video-Super-Resolution","date":"2023-05-03T08:07:04.000Z","updated":"2023-05-15T07:37:31.808Z","comments":true,"path":"2023/05/03/Learning-a-Deep-Dual-Attention-Network-for-Video-Super-Resolution/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/05/03/Learning-a-Deep-Dual-Attention-Network-for-Video-Super-Resolution/","excerpt":"","text":"Learning a Deep Dual Attention Network for Video Super-Resolution之前的方法在SR上 普遍通过降尺度运动估计来处理大的运动，由于降低了分辨率会有不利的影响。同时，类似的方法平等的处理不同类型的中间特征，这缺乏通过强调有意义的信息来揭示高频细节的灵活性。为此，提出了 deep dual attention network (DDAN) 包括：1.运动补偿网络MCNet2.SR重建网络RecenNet 充分利用其时空信息特征，实现精确的视频SR MCNet逐步学习光流表示，以金字塔的方式合成相邻帧的运动信息。为了减少基于光流的运动补偿引起的误配准误差，提取了原始LR相邻帧的细节分量作为补充信息，以进行准确的特征提取。在ReceonNet中，我们在一个Residual单元上实现了双注意机制，并形成了一个剩余注意单元，以关注高频细节恢复的中间信息特征。 之前网络存在的问题： 都通过分层卷积进行降尺度运动估计，以有效地处理大尺度，但是分辨率的降低会导致粗糙的光流表示 视频超分，简单地将相邻帧和中间帧连接起来进行SR重建。但是运动估计的不准确可能会导致配准误差。 较深的CNN网络中的特征包含不同的类型信息，即低频和高频分量。低频分量描述了图像的主要部分，高频分量负责边缘和纹理的细节。以前的方法平等地对待信息，缺乏灵活性来强调有意义的信息的高频细节恢复。 MCNet中提取原始LR相邻地细节分量作为补充信息，以更准确地提取特征，减少运动估计所带来的错误。 在ReconNet中我们提出了由多个残余注意块（RAB）组成的残余注意组（RAG），以增强我们的模型在高频细节恢复方面的特征表示能力。具体来说，在一个残差块上实现了双重注意机制，即通道注意和空间注意，并形成RAB。RAB可以自适应地处理中间特征 在 通道和空间域上。 方法总体分为运动补偿 和 重建 两个部分：1.运动补偿部对中间帧进行运动估计，并将预测的输出与相邻帧相减得到对应的残差以作为运动补偿的信息。2.重建部分将 运动补偿的运动估计 相邻帧残差的运动补偿 低分图像 三者作为输入进行图像的重建工作。 运动补偿网络：Motion Compensation Network学习降尺度比例的 motion flow之外，还开发了一个额外的运动估计模块以学习全分辨率的光流表示。 分三个尺度去学习中间帧I的运动估计，后将相邻帧T降采样到相同的scale后，计算对应的Warp。类似多尺度策略，将得到的warp信息上采样后传递到下一层更高分辨率的运动估计阶段中。 Detail Components Extraction通过 将相邻帧与原始低分帧相减的方式提取 相邻帧的细节分量Detail Components 重建网络：SR Reconstruction Network包含四个部分：1.特征提取2.多个堆叠的密集ConvLSTM块 as build module3.残差注意力模块RAM4.up scale模块 ResAttnModule: Attention Module中包含空间和通道注意力","categories":[],"tags":[{"name":"paper SR","slug":"paper-SR","permalink":"http://aifengdudexiaojie.github.io/tags/paper-SR/"}]},{"title":"Multi-scale and U-shaped Networks for Deblurring","slug":"Multi-scale-and-U-shaped-Networks-for-Deblurring","date":"2023-05-02T07:54:20.000Z","updated":"2023-05-02T10:00:29.759Z","comments":true,"path":"2023/05/02/Multi-scale-and-U-shaped-Networks-for-Deblurring/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/05/02/Multi-scale-and-U-shaped-Networks-for-Deblurring/","excerpt":"","text":"对提出的构及其对图像去模糊的影响比较。并提出一个NFResblock的Block。NFResblock 包括：1.快速傅里叶变换层2.一系列改进的非线性激活自由块组 同时改进了多尺度和U-Net架构 还使用三种不同的损失函数来训练这些架构：Charbonnier Loss, Edge Loss, Frequency Reconstruction Loss 引言NFResblock包括NAFBlock和FFT ResblockNFResnet是基于MIMO-Unet的 NFResnet+基于MultiScale结构动机为 模糊和清晰的图像对之间的高频和低频差异。 ResBlock可能有利于学习高频组件，但低频信息将不会被适当地建模。使用FFT Block [2]以及边缘和频率重建损失来解决这个挑战。 所提出的deblurring问题包括： 现实数据集 模糊图像中的long-range空间依赖 对模糊核的错误估计 处理轻微模糊的次优解 相关工作方法NFResblockFFT-ResBlock：相比于清晰图像，模糊图像有更多的低频信息。同时CNN的有效感受野较为有限(该部分可以联想到利用小波的分解来变相的扩大网络的感受野，从而提升网络的性能)。CNN中的ResBlock可能缺乏对低频的建模能力(有利于学习高频组件 残差结构)。因此，ResBlock未能捕获低频信息是减少模糊和清晰图像之间的不一致性的一个重要限制。为了解决这个问题，添加了另一个基于信道级快速傅里叶变换（FFT）的分支。这有助于捕获频域中的全局信息。首先，利用FFT将图像从空间域转换为频域。然后，像一个残差分支一样，频域特征被传递给卷积块，然后是一个非线性激活函数。 NAF Block：NAF Block[1]是一种新的非线性激活自由网络的卷积构建块，即NAFNet[1]。为了避免架构过于复杂，该Block avoid 使用任何激活函数。NAF Block 有两个变种：NAF-U &amp; NAF-D NFResnet+:多尺度结构，每个尺度上的input图都是前一张降采样本版。每层上都有NFResblocks。包括 NAF-U 和 NAF-D 将其放在卷积层之间形成残差结构。 两个变种NAF-U &amp; NAF-D 放在改进的Resblock中以成为NFResblock： 其中 NFResblock 的右侧分支为快速傅里叶变换 文章并未详细结构两个变种的设计动机，仅仅是改进非线性激活自由块 LOSS FUNC loss 方面加入了FFT 和 Edge 的监督 提升明显。数据集使用的是DVD补帧。 实验部分对NAFU&amp;D进行了补充：NAF-U：使用简单的通道注意力以捕捉long-range依赖NAF-D：去掉了重像素注意和通道注意模型，在NAF-D中使用简单门 NFResnet删除了特征注意模块、浅层卷积模块、额外的跳跃连接和在MIMO-Unet [15]中提出的编码器-解码器架构。为了保留MIMO的结构，我们使用一组包含正常卷积和NFResBlock的卷积块（参见图3），并将其命名为NFResNet+。因此，NFResNet有13.84M的参数，而NFResNet+（包含NAF-Down块）有13.60M的参数。 我们没有在我们的NFResNet+中使用完整的NAF结构，因为我们假设有一个特征注意层就足以让模型关注模糊的区域。我们观察到，在参数较少的NFResNet+的情况下，获得了更好的PSNR值。 较好的结果可能来源于删除了额外的功能注意模块和跳过连接。 文章没有NFResnet的网络结构图，难以判断其与MIMO-UNet的区别。一般的在MIMO-UNet上改进应为对ResBlock的替换以及文章中描述的删除部分。","categories":[],"tags":[{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"}]},{"title":"Beyond Deep Residual Learning for Image Restoration","slug":"[paper]Beyond-Deep-Residual-Learning-for-Image-Restoration","date":"2023-04-17T02:13:50.000Z","updated":"2023-04-17T09:19:02.683Z","comments":true,"path":"2023/04/17/[paper]Beyond-Deep-Residual-Learning-for-Image-Restoration/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/17/[paper]Beyond-Deep-Residual-Learning-for-Image-Restoration/","excerpt":"","text":"Beyond Deep Residual Learning for Image Restoration: Persistent Homology-Guided Manifold Simplification超越深度残余学习的图像恢复：持久同源引导流形简化 思想来源与依据：观察得到，if input和target 形式可以用更简单的拓扑结构映射到特征空间。&#x3D;&gt; 那么可以提升性能。 所提出的network architectures基于一个新的persistent homology(持续同源性)分析 on 残差学习 for 图像处理任务。证明了残差流形(residual manifold) 相比 原始图像流形(original image manifold)在拓扑结构上更加简单。&#x3D;&gt; 归功于残差学习的成功 从而提出了一种新的网络设计原则：manifold simplification 流形简化 具体来说：找到input和target数据集从原图到特征空间的映射。即将原数据集进行处理变换后可以变得更加简单容易学习。同时证明了小波变换在保持方向性的边缘信息(directional edge information)的同时提供了更加简单的拓扑上的流形结构(manifold structures)。 贡献： 提出了一种新的流形简化网络设计原理。 利用最近的一种称为持久同源的计算拓扑工具，我们证明了现有的残差学习是流形简化的一种特殊情况，然后提出了一个小波变换来简化输入和&#x2F;或标签流形的拓扑结构。 相关工作：A very deep residual encoder-decoder networks (RED-Net) was proposed for image restoration problems [21]. 残差学习的两种方式：1.使用skip connection2.将label data替换为 input和original label之间的差值 例如【32】 DnCNNs 理论Generalization bound 泛化边界将问题以公式描述 X-&gt;Y 描述为 $L(f)&#x3D;E_{D}||Y-f(X)||^2$ 表示风险 risk 其中D表示未知的概率分布 在神经网络中，经验风险由网络[27]的表示能力或容量决定，复杂度惩罚由网络的结构决定。结果表明，表示能力的容量相对于层数[27]呈指数增长，这证明了使用深度网络比使用浅层网络的合理性。然而，(1)中的复杂度惩罚也随着网络结构的增加而增加。对这种权衡的主要补救方法是使用大量的训练数据集，从而使复杂性惩罚的贡献更快地减少，从而使经验风险最小化（ERM）一致地收敛到风险最小化[28]。 本文最重要的贡献之一是通过使用一个相对更简单的网络，通过减少数据流形的复杂性来减少差距。 即从X-&gt;Y 变为X’-&gt;Y’ 其中 X′ &#x3D; Φ(X) Y′ &#x3D; Ψ(Y) 以上在第二种残差学习的方法中以Y-X的残差作为真值的方式 就是一种标签变换的方式。 残差的标签流形在拓扑上相比单独的Y更加简单。&#x3D;&gt;引入小波作为一种处理数据的方式。 以降低输入和真值的拓扑复杂度。由于小波矩的消失(vanishing moments of wavelets) 小波变换可以在保留图像边缘[8,20]的同时，消除平滑变化的信号，从而实现了降维和流形简化。 Persistent homology 持久同源性看不懂 所提结构首先 利用小波变换将输入图像进行小波分解为4个子带小波残差图作为新的标签真值。同样对真值图像进行小波变换，后与相应子带的输入图 进行相减操作得到。去噪取40-40patch","categories":[],"tags":[{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"}]},{"title":"Tensor to Image","slug":"[Daily Code]Tensor-to-Image","date":"2023-04-16T12:45:10.000Z","updated":"2023-04-17T09:22:03.422Z","comments":true,"path":"2023/04/16/[Daily Code]Tensor-to-Image/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/16/[Daily%20Code]Tensor-to-Image/","excerpt":"","text":"实现从张量到图片的保存： # pre 为预测的输出张量 # 处理pred数据 将其处理到0-1之间 pred_clip = torch.clamp(pred, 0, 1) save_name = os.path.join(config.result_dir, name[0]) # 将值变为0-255 pred_clip += 0.5 / 255 # tensor to image 的主要代码 # F.to_pil_image(tesnor in cpu, mode) pred = F.to_pil_image(pred_clip.squeeze(0).cpu(), &#39;L&#39;) # 保存图像 pred.save(save_name) 可以处理的mode类型 主要为 “L”:灰度图 “RGB”:3通道彩色图to_pil_image 的mode参数可参考官方文档","categories":[],"tags":[{"name":"daily code","slug":"daily-code","permalink":"http://aifengdudexiaojie.github.io/tags/daily-code/"}]},{"title":"An Efficient Approach for Underwater Image Improvement","slug":"[paper]An-Efficient-Approach-for-Underwater-Image-Improvement","date":"2023-04-15T09:18:55.000Z","updated":"2023-04-17T00:47:05.542Z","comments":true,"path":"2023/04/15/[paper]An-Efficient-Approach-for-Underwater-Image-Improvement/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/15/[paper]An-Efficient-Approach-for-Underwater-Image-Improvement/","excerpt":"","text":"An Efficient Approach for Underwater Image Improvement: Deblurring,Dehazing, and Color Correction目的：为实现实时的处理，需要以一个小的 编码-解码 结构 来处理水下图像 并保持效率使用 离散小波的skip connection 和 通道注意力 来解决 haze 和 color correction 意图通过 DWT完成下采样和skip connection for 增加解码器的可访问信息DWT 带来了通道扩充 &#x3D;&gt; 使用通道和空间注意力块 CBAM作为一种有效的方式以提高颜色恢复的效果。 文章认为：CBAM有助于将多个特征通道表示为 相关的颜色通道。 相关工作【5】发现了 在子带上学习的好处小波残差网络可以在额外的频率子带上进行学习，增加了模型的表征能力。在skip connection 中维持更多的高频信息 允许网络更好地重建deblur图像。 方法首先，采用DWT增强跳跃连接，同时在编码器中进行下采样 以 &lt;维持高频组件？&gt; in dehazing 其次，在卷积之间使用 CBAM 来调整网络结构 此外，在网络中添加了并行地deblurring Res2Net【17】 结构 with 额外的全局跳跃连接。其效果超越了单纯的Res2Net 其中 低频分量通过通过下采样卷积实现。 高频分量通过Haar滤波器得到。高频的skip connection + 解码端的反卷积upsample 使得网络同时在空间域和频域进行学习。 Deblurring Branch使用改进过的结构与原有的网络合并得到最终的模型。即两个分支并行处理。for 预测一个残差图通过求和summation 将该分支的 knowledge 融入DWT分支。 梯度惩罚将补偿图像质量。使用轻量级的CNN【17】","categories":[],"tags":[{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"}]},{"title":"opencv pil numpy","slug":"[Daily Code]Opencv PIL Numpy","date":"2023-04-14T11:50:00.000Z","updated":"2023-04-17T09:25:49.081Z","comments":true,"path":"2023/04/14/[Daily Code]Opencv PIL Numpy/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/14/[Daily%20Code]Opencv%20PIL%20Numpy/","excerpt":"","text":"代码高亮问题处理link将highlight.enable 和 prismjs.enable 均设置为 false opencv 读取图片并转为numpy 再转为图像保存： # 读取图像 im = cv2.imread(&#39;test.jpg&#39;) # 图像无shape 使用size print(im.size) # 将图像转为对应数组 im_numpy = np.array(im) print(im_numpy.shape) # 保存numpy 数据为npy格式 np.save(&#39;save_numpy&#39;, im_numpy) # numpy转回图像进行展示 cv2.imshow(&quot;im&quot;, np.uint8(im_numpy)) # 保存numpy为图像 cv2.imwrite(&quot;save_name&quot;, im_numpy) PIL 读取图片并转为numpy 再转为图像保存： # 读取图像 im = Image.open(&#39;test.jpg&#39;) # 展示图像 plt.title(&quot;img&quot;) plt.imshow(im) plt.show() # 将图像转为对应数组 im_numpy = np.array(im) print(im_numpy.shape) # numpy转回图像进行展示 im = Image.fromarray(im_numpy) # 保存numpy为图像 im.save(&quot;save_name&quot;)","categories":[],"tags":[{"name":"daily code","slug":"daily-code","permalink":"http://aifengdudexiaojie.github.io/tags/daily-code/"}]},{"title":"DIFFICULTY-AWARE IMAGE SUPER RESOLUTION VIA DEEP ADAPTIVE DUAL-NETWORK","slug":"[paper]Difficulty-aware Image Super Resolution","date":"2023-04-10T16:00:00.000Z","updated":"2023-04-12T08:48:42.335Z","comments":true,"path":"2023/04/11/[paper]Difficulty-aware Image Super Resolution/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/11/[paper]Difficulty-aware%20Image%20Super%20Resolution/","excerpt":"","text":"DIFFICULTY-AWARE IMAGE SUPER RESOLUTION VIA DEEP ADAPTIVE DUAL-NETWORK在不考虑难度多样性的情况下平等地对待所有区域，目前已经触及顶端极限了。为了解决以上问题，提出了一种方法来区分图像内每个图像区域难度。 提出一种双向SR网络。分别聚焦简单和困难 处理区域。争对如何判断一个区域地难易，提出了一种基于PSNR先验地图像难度识别网络。来自适应地强制执行双向SR网络。 Code and results are available at here 【7】利用简化的残差块建立了巨大的SR模型EDSR，对恢复质量有了很大的提高【14】提出了基于残差密集块（RDB）的残差密集网络（RDN）来充分利用所有卷积层的层次特征。【10】提出了一种残差（RIR）来解决训练深度SR网络的困难，并提出了一种信道注意机制，通过区分跨信道处理丰富的低频信息来提高SR网络的表示能力。 存在的问题：使用统一的模型来处理图像的所有区域。一般来说图像存在平滑区域，该部分去实现高分是简单的。&#x3D;&gt;模糊图像中包含有较小模糊的区域 相似的 这部分是相对好处理的，且该部分需要集中处理的是高频部分。重模型相对简单模型在容易处理的区域的效果并不好。 文章的主要贡献： 我们提出了一个图像难度识别网络，该网络充分探索了PSNR先验知识，提出了一个精确的难度分类。 提出了一种新的困难感知SR方法，该方法可以区分地处理图像的每个区域以实现精确的SR 方法三个主要模块： 划分困难程度的 difficulty identifier module DIM 掩码生成器 mask generator 双SR网络 dual-way SR network DIM用于识别图像 regions&#x2F;patches 的超分难度 以及之后的 mask 生成 Dual-way SR部分包含两个独立的SR模型 分别记为CB 处理困难patches 和 PB 处理简单patches 首先将LR低分的完整图像分割成48-48的patches，然后将补丁输入到DIM中DIM对每一个patch做难易的判断 表现为给其一个难度概率向量(属于某个难度的可能性)。 最终两个分支处理相应的部分后，由mask 生成器去自适应地选择 HR patches 去填充帮助恢复full image Difficulty Identifier Module DIM使用双边缘(Bicubic) PSNR 得分作为SR难度指标 为了利用先验PSNR知识，将SR困难识别问题建模为一个分类问题。使用LeNet作为DIM地基本主干来训练DIM 具体的：采用Bicubic PSNR值作为 target标签用于训练 首先从数据集中裁剪HR 和 LR 对，用Bicubic upscale patches 然后，我们计算所有样本的Bicubic PSNR值，并将其值分为5类，然后将patches 的难度难度级别转变为一个一维的向量 one-hot vector 对于每个patch的输出是一个概率向量{p1,p2,p3,p4,p5} Mask GeneratorMask 利用概率向量来帮助 framework 强制执行 dual-way SR 其mask的使用 应用在网络之后，以实现对特征区域的挑选弥补。mask的生成 根据p1的概率决定：$$mask(\\hat{y}) &#x3D; \\begin{cases}1, &amp; max(\\hat{y})&lt;&#x3D;&#x3D;p_{1} \\0, &amp; otherwise\\\\end{cases}$$ 从而dual-way SR的自适应过程可以描述为：$I_{sr}&#x3D;(1-mask)×F_{CB}(I_{lr})+mask×F_{PB}(I_{lr})$ 即mask为1的区域是hard-level 较低的区域 Complex Branch and Plain BranchCB 部分的 网络为 IDN Bicubic interpolation 作为 PB 的分支处理 优势： GPU并行计算 可以替换两个分支的主干网络以达到跟好的性能","categories":[],"tags":[{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"}]},{"title":"电影推荐 演员推荐","slug":"[other]Movies and Actors","date":"2023-04-10T16:00:00.000Z","updated":"2023-05-25T12:59:16.283Z","comments":true,"path":"2023/04/11/[other]Movies and Actors/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/11/[other]Movies%20and%20Actors/","excerpt":"","text":"电影下载网站MP4网迅雷磁力连接 演员中国日本安藤樱 《小偷家族》# 《百元之恋》 《重启人生》* 韩国黄政民 《当男人恋爱时》# 《国际市场》# 《新世界》 《老手》# 车太贤 《与神同行：罪与罚》# 电影《钢琴家》# B站 《白日梦想家》 百度云 cr4e 爱奇艺 《海边的曼彻斯特》百度云 《春宵苦短，少女前进吧》# 百度云 umt6 《预告犯》# 百度云 3hf1","categories":[],"tags":[{"name":"other","slug":"other","permalink":"http://aifengdudexiaojie.github.io/tags/other/"}]},{"title":"Wavelet-Based Dual-Branch Network for Image Demoireing","slug":"[paper]Wavelet-Based Dual-Branch Network for Image Demoireing","date":"2023-04-10T16:00:00.000Z","updated":"2023-04-12T08:49:03.542Z","comments":true,"path":"2023/04/11/[paper]Wavelet-Based Dual-Branch Network for Image Demoireing/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/11/[paper]Wavelet-Based%20Dual-Branch%20Network%20for%20Image%20Demoireing/","excerpt":"","text":"Wavelet-Based Dual-Branch Network for Image Demoireing双分支的方法用模块实现。分别为dense 和 dilated 分支 分别用于存储close-range 和 far-range 信息 文章的主要贡献： 所提出的基于小波的双分支网络 方向感知模块 DPM 用于突出摩尔纹区域 相关工作小波方法：有方法认为将小波变换和其逆变换可以视为 池化与非池化层 可以保存其结构信息。 双分支方法：【40】对困难与简单处理的区域进行的划分 for 超分任务 纹理移除方法：使用局部滤波器的方法试图删除某些纹理，可同时保持其他高频结构 方法模块内两个分支 两个分支分别处理不同的频率范围密集分支用于 close-range 纹理 膨胀分支用于 far-range 纹理 发现较高频域包含的摩尔纹较少&#x3D;&gt;为恢复摩尔纹提供关键信息。 整体方法：小波变换等级设置为2。原始RGB输入被转化为48个子带，每个颜色通道转为16个通道 将高低两个频子带链接起来，而非单独处理每个频带。因为每个图像的退化模式差异很大，很难找到手动的阈值进行分离。 密集分支通过旁路链接设计+特征重用从RDN【69】中的残差块中添加一个DPM 方向感知模块 每个残余块包含2个小模块 每个小模块包含5个卷积，每层的输入包含之前所有层的输出 DPM用于寻找摩尔纹的方向，其输出和每个密集块的输出相乘，以加权的方式融入到后面的输入中。 ### 膨胀卷积 用膨胀卷积克服下采样以及池化带来的细节损失 for 更好的感受野 该部分仅包含两层： - 3×3膨胀卷积 - 3×3卷积 为了应对出现的网格效应，一般的混合设计不适应。 采取【1，2，3，5，8，13，21】7个不同的膨胀率，同时应用一些香草卷积进一步减少网格伪影。 DPM使用DPM来生成注意力图，以突出摩尔纹的空间分布，并施以监督。8个方向+两个卷积层 相当于注意力操作。其权重系数由输入的特征经过卷积处理后得到。认为其方向信息的突出作用仅在第二阶段才表现 LOSS FUNCL1 + 感知 + 小波损失 Wavelet Loss:在子带层面上使用MSE计算 将高低频区分开进行计算。同时为了防止小波系数收敛到0设置一个下限$l_{detail}$$L_{wavelet}&#x3D;l_{MSE}+l_{detail}$ Attention LOSS$L_{a}&#x3D;||A-d(M)||^{2}_{2}$ 其中A是DPM输出 in network M是摩尔纹的mask，为摩尔纹图像与真值之间的差值 并通过了一定的阈值计算 d(.)为下采样操作以确保尺寸对齐 实验256-256 3 通过Haar 得到48个大小为64-64小波子带 使用7个双分支模块 DPM 添加到第4个密集分支中以感知摩尔纹理 lr 2&gt;-4 每20 epoch 除10 消融实验膨胀卷积的提升相对较大，DPM与小波变换和逆变换提升较为明显","categories":[],"tags":[{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"}]}],"categories":[],"tags":[{"name":"paper wavelet","slug":"paper-wavelet","permalink":"http://aifengdudexiaojie.github.io/tags/paper-wavelet/"},{"name":"wavelet sod","slug":"wavelet-sod","permalink":"http://aifengdudexiaojie.github.io/tags/wavelet-sod/"},{"name":"paper dual-branch denoising","slug":"paper-dual-branch-denoising","permalink":"http://aifengdudexiaojie.github.io/tags/paper-dual-branch-denoising/"},{"name":"paper multi-branch defocus","slug":"paper-multi-branch-defocus","permalink":"http://aifengdudexiaojie.github.io/tags/paper-multi-branch-defocus/"},{"name":"paper SR","slug":"paper-SR","permalink":"http://aifengdudexiaojie.github.io/tags/paper-SR/"},{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"},{"name":"daily code","slug":"daily-code","permalink":"http://aifengdudexiaojie.github.io/tags/daily-code/"},{"name":"other","slug":"other","permalink":"http://aifengdudexiaojie.github.io/tags/other/"}]}