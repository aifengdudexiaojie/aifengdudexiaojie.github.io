{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://aifengdudexiaojie.github.io","root":"/"},"pages":[],"posts":[{"title":"Tensor to Image","slug":"[Daily Code]Tensor-to-Image","date":"2023-04-16T12:45:10.000Z","updated":"2023-04-16T13:02:29.376Z","comments":true,"path":"2023/04/16/[Daily Code]Tensor-to-Image/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/16/[Daily%20Code]Tensor-to-Image/","excerpt":"","text":"实现从张量到图片的保存： # pre 为预测的输出张量 # 处理pred数据 将其处理到0-1之间 pred_clip = torch.clamp(pred, 0, 1) save_name = os.path.join(config.result_dir, name[0]) # 将值变为0-255 pred_clip += 0.5 / 255 # tensor to image 的主要代码 # F.to_pil_image(tesnor in cpu, mode) pred = F.to_pil_image(pred_clip.squeeze(0).cpu(), &#39;L&#39;) # 保存图像 pred.save(save_name) 可以处理的mode类型 主要为 “L”:灰度图 “RGB”:3通道彩色图to_pil_image 的mode参数可参考官方文档","categories":[],"tags":[{"name":"daily code","slug":"daily-code","permalink":"http://aifengdudexiaojie.github.io/tags/daily-code/"}]},{"title":"An Efficient Approach for Underwater Image Improvement","slug":"[paper]An-Efficient-Approach-for-Underwater-Image-Improvement","date":"2023-04-15T09:18:55.000Z","updated":"2023-04-16T13:02:12.262Z","comments":true,"path":"2023/04/15/[paper]An-Efficient-Approach-for-Underwater-Image-Improvement/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/15/[paper]An-Efficient-Approach-for-Underwater-Image-Improvement/","excerpt":"","text":"An Efficient Approach for Underwater Image Improvement: Deblurring,Dehazing, and Color Correction目的：为实现实时的处理，需要以一个小的 编码-解码 结构 来处理水下图像 并保持效率使用 离散小波的skip connection 和 通道注意力 来解决 haze 和 color correction 意图通过 DWT完成下采样和skip connection for 增加解码器的可访问信息DWT 带来了通道扩充 &#x3D;&gt; 使用通道和空间注意力块 CBAM作为一种有效的方式以提高颜色恢复的效果。 文章认为：CBAM有助于将多个特征通道表示为 相关的颜色通道。 相关工作【5】发现了 在子带上学习的好处小波残差网络可以在额外的频率子带上进行学习，增加了模型的表征能力。在skip connection 中维持更多的高频信息 允许网络更好地重建deblur图像。 方法首先，采用DWT增强跳跃连接，同时在编码器中进行下采样 以 &lt;维持高频组件？&gt; in dehazing 其次，在卷积之间使用 CBAM 来调整网络结构 此外，在网络中添加了并行地deblurring Res2Net【17】 结构 with 额外的全局跳跃连接。其效果超越了单纯的Res2Net 其中 低频分量通过通过下采样卷积实现。 高频分量通过Haar滤波器得到。高频的skip connection + 解码端的反卷积upsample 使得网络同时在空间域和频域进行学习。 Deblurring Branch使用改进过的结构与原有的网络合并得到最终的模型。即两个分支并行处理。for 预测一个残差图通过求和summation 将该分支的 knowledge 融入DWT分支。 梯度惩罚将补偿图像质量。使用轻量级的CNN【17】","categories":[],"tags":[{"name":"papaer","slug":"papaer","permalink":"http://aifengdudexiaojie.github.io/tags/papaer/"}]},{"title":"opencv pil numpy","slug":"[DailyCode]Opencv PIL Numpy","date":"2023-04-14T11:50:00.000Z","updated":"2023-04-16T12:52:58.280Z","comments":true,"path":"2023/04/14/[DailyCode]Opencv PIL Numpy/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/14/[DailyCode]Opencv%20PIL%20Numpy/","excerpt":"","text":"代码高亮问题处理link将highlight.enable 和 prismjs.enable 均设置为 false opencv 读取图片并转为numpy 再转为图像保存： # 读取图像 im = cv2.imread(&#39;test.jpg&#39;) # 图像无shape 使用size print(im.size) # 将图像转为对应数组 im_numpy = np.array(im) print(im_numpy.shape) # 保存numpy 数据为npy格式 np.save(&#39;save_numpy&#39;, im_numpy) # numpy转回图像进行展示 cv2.imshow(&quot;im&quot;, np.uint8(im_numpy)) # 保存numpy为图像 cv2.imwrite(&quot;save_name&quot;, im_numpy) PIL 读取图片并转为numpy 再转为图像保存： # 读取图像 im = Image.open(&#39;test.jpg&#39;) # 展示图像 plt.title(&quot;img&quot;) plt.imshow(im) plt.show() # 将图像转为对应数组 im_numpy = np.array(im) print(im_numpy.shape) # numpy转回图像进行展示 im = Image.fromarray(im_numpy) # 保存numpy为图像 im.save(&quot;save_name&quot;)","categories":[],"tags":[{"name":"daily code","slug":"daily-code","permalink":"http://aifengdudexiaojie.github.io/tags/daily-code/"}]},{"title":"DIFFICULTY-AWARE IMAGE SUPER RESOLUTION VIA DEEP ADAPTIVE DUAL-NETWORK","slug":"[paper]Difficulty-aware Image Super Resolution","date":"2023-04-10T16:00:00.000Z","updated":"2023-04-12T08:48:42.335Z","comments":true,"path":"2023/04/11/[paper]Difficulty-aware Image Super Resolution/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/11/[paper]Difficulty-aware%20Image%20Super%20Resolution/","excerpt":"","text":"DIFFICULTY-AWARE IMAGE SUPER RESOLUTION VIA DEEP ADAPTIVE DUAL-NETWORK在不考虑难度多样性的情况下平等地对待所有区域，目前已经触及顶端极限了。为了解决以上问题，提出了一种方法来区分图像内每个图像区域难度。 提出一种双向SR网络。分别聚焦简单和困难 处理区域。争对如何判断一个区域地难易，提出了一种基于PSNR先验地图像难度识别网络。来自适应地强制执行双向SR网络。 Code and results are available at here 【7】利用简化的残差块建立了巨大的SR模型EDSR，对恢复质量有了很大的提高【14】提出了基于残差密集块（RDB）的残差密集网络（RDN）来充分利用所有卷积层的层次特征。【10】提出了一种残差（RIR）来解决训练深度SR网络的困难，并提出了一种信道注意机制，通过区分跨信道处理丰富的低频信息来提高SR网络的表示能力。 存在的问题：使用统一的模型来处理图像的所有区域。一般来说图像存在平滑区域，该部分去实现高分是简单的。&#x3D;&gt;模糊图像中包含有较小模糊的区域 相似的 这部分是相对好处理的，且该部分需要集中处理的是高频部分。重模型相对简单模型在容易处理的区域的效果并不好。 文章的主要贡献： 我们提出了一个图像难度识别网络，该网络充分探索了PSNR先验知识，提出了一个精确的难度分类。 提出了一种新的困难感知SR方法，该方法可以区分地处理图像的每个区域以实现精确的SR 方法三个主要模块： 划分困难程度的 difficulty identifier module DIM 掩码生成器 mask generator 双SR网络 dual-way SR network DIM用于识别图像 regions&#x2F;patches 的超分难度 以及之后的 mask 生成 Dual-way SR部分包含两个独立的SR模型 分别记为CB 处理困难patches 和 PB 处理简单patches 首先将LR低分的完整图像分割成48-48的patches，然后将补丁输入到DIM中DIM对每一个patch做难易的判断 表现为给其一个难度概率向量(属于某个难度的可能性)。 最终两个分支处理相应的部分后，由mask 生成器去自适应地选择 HR patches 去填充帮助恢复full image Difficulty Identifier Module DIM使用双边缘(Bicubic) PSNR 得分作为SR难度指标 为了利用先验PSNR知识，将SR困难识别问题建模为一个分类问题。使用LeNet作为DIM地基本主干来训练DIM 具体的：采用Bicubic PSNR值作为 target标签用于训练 首先从数据集中裁剪HR 和 LR 对，用Bicubic upscale patches 然后，我们计算所有样本的Bicubic PSNR值，并将其值分为5类，然后将patches 的难度难度级别转变为一个一维的向量 one-hot vector 对于每个patch的输出是一个概率向量{p1,p2,p3,p4,p5} Mask GeneratorMask 利用概率向量来帮助 framework 强制执行 dual-way SR 其mask的使用 应用在网络之后，以实现对特征区域的挑选弥补。mask的生成 根据p1的概率决定：$$mask(\\hat{y}) &#x3D; \\begin{cases}1, &amp; max(\\hat{y})&lt;&#x3D;&#x3D;p_{1} \\0, &amp; otherwise\\\\end{cases}$$ 从而dual-way SR的自适应过程可以描述为：$I_{sr}&#x3D;(1-mask)×F_{CB}(I_{lr})+mask×F_{PB}(I_{lr})$ 即mask为1的区域是hard-level 较低的区域 Complex Branch and Plain BranchCB 部分的 网络为 IDN Bicubic interpolation 作为 PB 的分支处理 优势： GPU并行计算 可以替换两个分支的主干网络以达到跟好的性能","categories":[],"tags":[{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"}]},{"title":"电影推荐 演员推荐","slug":"[other]Movies and Actors","date":"2023-04-10T16:00:00.000Z","updated":"2023-04-12T08:47:20.813Z","comments":true,"path":"2023/04/11/[other]Movies and Actors/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/11/[other]Movies%20and%20Actors/","excerpt":"","text":"演员中国日本安藤樱 《小偷家族》# 《百元之恋》 《重启人生》* 韩国黄政民 《当男人恋爱时》# 《国际市场》# 《新世界》 《老手》# 车太贤 《与神同行：罪与罚》# 电影《钢琴家》# B站 《白日梦想家》 百度云 cr4e 爱奇艺 《海边的曼彻斯特》百度云 《春宵苦短，少女前进吧》# 百度云 umt6 《预告犯》# 百度云 3hf1","categories":[],"tags":[{"name":"other","slug":"other","permalink":"http://aifengdudexiaojie.github.io/tags/other/"}]},{"title":"Wavelet-Based Dual-Branch Network for Image Demoireing","slug":"[paper]Wavelet-Based Dual-Branch Network for Image Demoireing","date":"2023-04-10T16:00:00.000Z","updated":"2023-04-12T08:49:03.542Z","comments":true,"path":"2023/04/11/[paper]Wavelet-Based Dual-Branch Network for Image Demoireing/","link":"","permalink":"http://aifengdudexiaojie.github.io/2023/04/11/[paper]Wavelet-Based%20Dual-Branch%20Network%20for%20Image%20Demoireing/","excerpt":"","text":"Wavelet-Based Dual-Branch Network for Image Demoireing双分支的方法用模块实现。分别为dense 和 dilated 分支 分别用于存储close-range 和 far-range 信息 文章的主要贡献： 所提出的基于小波的双分支网络 方向感知模块 DPM 用于突出摩尔纹区域 相关工作小波方法：有方法认为将小波变换和其逆变换可以视为 池化与非池化层 可以保存其结构信息。 双分支方法：【40】对困难与简单处理的区域进行的划分 for 超分任务 纹理移除方法：使用局部滤波器的方法试图删除某些纹理，可同时保持其他高频结构 方法模块内两个分支 两个分支分别处理不同的频率范围密集分支用于 close-range 纹理 膨胀分支用于 far-range 纹理 发现较高频域包含的摩尔纹较少&#x3D;&gt;为恢复摩尔纹提供关键信息。 整体方法：小波变换等级设置为2。原始RGB输入被转化为48个子带，每个颜色通道转为16个通道 将高低两个频子带链接起来，而非单独处理每个频带。因为每个图像的退化模式差异很大，很难找到手动的阈值进行分离。 密集分支通过旁路链接设计+特征重用从RDN【69】中的残差块中添加一个DPM 方向感知模块 每个残余块包含2个小模块 每个小模块包含5个卷积，每层的输入包含之前所有层的输出 DPM用于寻找摩尔纹的方向，其输出和每个密集块的输出相乘，以加权的方式融入到后面的输入中。 ### 膨胀卷积 用膨胀卷积克服下采样以及池化带来的细节损失 for 更好的感受野 该部分仅包含两层： - 3×3膨胀卷积 - 3×3卷积 为了应对出现的网格效应，一般的混合设计不适应。 采取【1，2，3，5，8，13，21】7个不同的膨胀率，同时应用一些香草卷积进一步减少网格伪影。 DPM使用DPM来生成注意力图，以突出摩尔纹的空间分布，并施以监督。8个方向+两个卷积层 相当于注意力操作。其权重系数由输入的特征经过卷积处理后得到。认为其方向信息的突出作用仅在第二阶段才表现 LOSS FUNCL1 + 感知 + 小波损失 Wavelet Loss:在子带层面上使用MSE计算 将高低频区分开进行计算。同时为了防止小波系数收敛到0设置一个下限$l_{detail}$$L_{wavelet}&#x3D;l_{MSE}+l_{detail}$ Attention LOSS$L_{a}&#x3D;||A-d(M)||^{2}_{2}$ 其中A是DPM输出 in network M是摩尔纹的mask，为摩尔纹图像与真值之间的差值 并通过了一定的阈值计算 d(.)为下采样操作以确保尺寸对齐 实验256-256 3 通过Haar 得到48个大小为64-64小波子带 使用7个双分支模块 DPM 添加到第4个密集分支中以感知摩尔纹理 lr 2&gt;-4 每20 epoch 除10 消融实验膨胀卷积的提升相对较大，DPM与小波变换和逆变换提升较为明显","categories":[],"tags":[{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"}]}],"categories":[],"tags":[{"name":"daily code","slug":"daily-code","permalink":"http://aifengdudexiaojie.github.io/tags/daily-code/"},{"name":"papaer","slug":"papaer","permalink":"http://aifengdudexiaojie.github.io/tags/papaer/"},{"name":"paper","slug":"paper","permalink":"http://aifengdudexiaojie.github.io/tags/paper/"},{"name":"other","slug":"other","permalink":"http://aifengdudexiaojie.github.io/tags/other/"}]}